{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prewhiten(x):\n",
    "    \"\"\"\n",
    "    normalize the input\n",
    "    \"\"\"\n",
    "    if x.ndim == 4:\n",
    "        axis = (1, 2, 3)\n",
    "        size = x[0].size\n",
    "    elif x.ndim == 3:\n",
    "        axis = (0, 1, 2)\n",
    "        size = x.size\n",
    "    else:\n",
    "        raise ValueError(\"Dimension should be 3 or 4\")\n",
    "\n",
    "    mean = np.mean(x, axis=axis, keepdims=True)\n",
    "    std = np.std(x, axis=axis, keepdims=True)\n",
    "    std_adj = np.maximum(std, 1.0 / np.sqrt(size))\n",
    "    y = (x - mean) / std_adj\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cascade = cv2.CascadeClassifier(\"models/haarcascade_frontalface.xml\")\n",
    "model = load_model(\"models/facenet_keras.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"images/test/test1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"images/test/test5.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "margin_half = 5\n",
    "\n",
    "boxes = cascade.detectMultiScale(image, 1.1, 4)\n",
    "\n",
    "aligned_images = []\n",
    "for box in boxes:\n",
    "    x, y, w, h = box\n",
    "    cropped = image[y - margin_half:y + h + margin_half, x - margin_half:x + w + margin_half, :]\n",
    "    aligned = cv2.resize(cropped, (160, 160))\n",
    "    aligned_images.append(aligned)\n",
    "\n",
    "aligned_images = np.array(aligned_images)\n",
    "prewhiten_images = prewhiten(aligned_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = model.predict(prewhiten_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_on_batch khi chạy lần đầu chậm nhưng những lần sau tốc độ tốt hơn predict\n",
    "# tuy nhiên nếu các batch có kích thước khác nhau thì với mỗi kích thước batch phải khởi tạo một lần\n",
    "# chẳng hạn có 3 loại ảnh là ảnh có 1, 2, 3 khuôn mặt thì phải khởi tạo ba lần\n",
    "predicts = model.predict_on_batch(prewhiten_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
